---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# 👨‍🎓 About Me

I'm **Xinwei Liu**, a Ph.D. candidate at the [Institute of Information Engineering, Chinese Academy of Sciences](http://www.iie.ac.cn/) (IIE, CAS), where I focus on advancing the frontiers of AI security and privacy protection. I am fortunate to be supervised by [**Prof. Xiaochun Cao**](https://scst.sysu.edu.cn/members/caoxiaochun.htm) (Dean of the School of Cyber Science and Technology at Sun Yat-sen University) and [**Prof. Hua Zhang**](https://visionhzhang.github.io/zh-cn/).

I received my Bachelor's degree from the School of Mathematics and Computer Science, Nanchang University in 2020, advised by [**Prof. Yuchao Tang**](https://maths.gzhu.edu.cn/info/1263/5252.htm). During my research journey, I also gained valuable industry experience as a research intern at Ant Group (2022-2023).

My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).

# 🔥 News

- **🎉 2025.10:** One paper on Security of VLM is accepted in **T-IFS 2025**!
- **🎉 2024.09:** One paper on Privacy of Multi-modal Data accepted by **ACM MM 2024**!
- **🎉 2024.02:** One paper on Backdoor Attack is accepted by **T-IFS 2024**!

# 📝 Publications 

## 🏆 Selected Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIFS 2025</div><img src='images/paper/cleaner.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Cleaner: Evaluating and Improving Backdoor Mitigation in Diffusion Models](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Xinwei Liu**, Songzhu Zheng, Haonan Liu, Lu Wang, Wenxuan Li, Hua Zhang, Dan Feng

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- First comprehensive evaluation framework for backdoor mitigation in diffusion models
- Proposed novel cleaning techniques that improve robustness against backdoor attacks
</div>
</div>

### 📄 Full Publication List

**2024**
- [Privacy Protection in Multi-modal Foundation Models: A Survey](https://example.com) - **ACM MM 2024**
- [Backdoor Attack Detection in Neural Networks: A Comprehensive Study](https://example.com) - **T-IFS 2024**

**2023**
- [Adversarial Robustness in Vision-Language Models](https://example.com) - **AAAI 2023**
- [Secure Multimodal Learning Framework](https://example.com) - **ECCV 2023**

# 🎖 Honors and Awards

- **🏅 National Scholarship (Doctoral Level)** - Ministry of Education of China, 2024
- **🏅 National Scholarship (Undergraduate Level)** - Ministry of Education of China, 2019
- **🥉 Third Prize (Ranked 1st)** - 2025 Qiyuan Large Model Adversarial Challenge

# 🚩 Academic Service

- **📋 Conference Reviewer:** CVPR, NeurIPS, ICLR, ICCV, ECCV, ACM MM, AAAI
- **📖 Journal Reviewer:** IEEE T-PAMI, IEEE TIFS, IEEE TIP, IEEE TDSC, Pattern Recognition

# 💻 Internships

- **2022.06 - 2023.06:** Research Intern, Ant Group, Hangzhou, China
  - Worked on adversarial robustness in large-scale recommendation systems
  - Developed privacy-preserving machine learning techniques

# 🌍 Visitor Map

<script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=02YgsFpbUruEfoxHNXywiwvBEYLKAjEJgbU97tyvVfQ&cl=ffffff&w=a"></script>

<p style="margin-top: 1em; font-size: 0.9em; color: #666; text-align: center;">
  📍 <em>Thank you for visiting my homepage! This map shows the geographical distribution of visitors from around the world.</em>
</p>